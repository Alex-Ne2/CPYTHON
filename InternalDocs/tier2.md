# The Tier 2 Interpreter

The [basic interpreter](interpreter.md), also referred to as the `tier 1`
interpreter, consists of a main loop that executes the bytecode instructions
generated by the [bytecode compiler](compiler.md) and their
[specializations](interpreter.md#Specialization). Runtime optimization in tier 1
can only be done for one instruction at a time. The `tier 2` interpreter is
based on a mechanism to replace an entire sequence of bytecode instructions,
and this enables optimizations that span multiple instructions.

## The Optimizer and Executors

The program begins running in tier 1, until a `JUMP_BACKWARD` instruction
determines that it is `hot` because the counter in its
[inline cache](interpreter.md#inline-cache-entries) indicates that is
executed more than some threshold number of times (see
[`backoff_counter_triggers`](../Include/internal/pycore_backoff.h)).
It then calls the function `_PyOptimizer_Optimize()` in
[`Python/optimizer.c`](../Python/optimizer.c), passing it the current
[frame](frames.md) and instruction pointer. `_PyOptimizer_Optimize()`
constructs an object of type
[`_PyExecutorObject`](Include/internal/pycore_optimizer.h) which implements
an optimized version of the instruction trace beginning at this jump.

The optimizer determines where the trace ends, and the executor is set up
to either return to `tier 1` and resume execution, or transfer control
to another executor (see `_PyExitData` in Include/internal/pycore_optimizer.h).

The executor is stored on the [`code object`](code_objects.md) of the frame,
in the `co_executors` field which is an array of executors. The start
instruction of the trace (the `JUMP_BACKWARD`) is replaced by an
`ENTER_EXECUTOR` instruction whose `oparg` is equal to the index of the
executor in `co_executors`.

## The uop optimizer

The optimizer that `_PyOptimizer_Optimize()` runs is configurable
via the `_Py_SetTier2Optimizer()` function (this is used in test
via `_testinternalcapi.set_optimizer()`.)

The tier 2 optimizer, `_PyUOpOptimizer_Type`, is defined in
[`Python/optimizer.c`](../Python/optimizer.c). It translates
an instruction trace into a sequence of micro-ops by replacing
each bytecode by an equivalent sequence of micro-ops
(see `_PyOpcode_macro_expansion` in
[pycore_opcode_metadata.h](../Include/internal/pycore_opcode_metadata.h)
which is generated from [`Python/bytecodes.c`](../Python/bytecodes.c)).
The micro-op sequence is then optimized by
`_Py_uop_analyze_and_optimize` in
[`Python/optimizer_analysis.c`](../Python/optimizer_analysis.c)
and a `_PyUOpExecutor_Type` is created to contain it.

## Running a uop executor on the tier 2 interpreter

After a tier 1 `JUMP_BACKWARD` instruction invokes the uop optimizer
to create a tier 2 uop executor, it transfers control to this executor
via the `GOTO_TIER_TWO` macro.

When tier 2 is enabled but the JIT is not (python was configured with
[`--enable-experimental-jit=interpreter`](https://docs.python.org/dev/using/configure.html#cmdoption-enable-experimental-jit)),
the executor jumps to `tier2_dispatch:` in
[`Python/ceval.c`](../Python/ceval.c), where there is a loop that
executes the micro-ops. The micro-ops are are defined in
[`Python/executor_cases.c.h`](../Python/executor_cases.c.h),
which is generated by the build script
[`Tools/cases_generator/tier2_generator.py`](../Tools/cases_generator/tier2_generator.py)
from the bytecode definitions in
[`Python/bytecodes.c`](../Python/bytecodes.c).
This loop exits when an `_EXIT_TRACE` or `_DEOPT` uop is reached,
and execution returns to teh tier 1 interpreter.

## Invalidating Executors

In addition to being stored on the code object, each executor is also
inserted into a list of all executors which is stored in the interpreter
state's `executor_list_head` field. This list is used when it is necessary
to invalidate executors because values that their construction depended
on may have changed.

## The JIT

When the jit is enabled (python was configured with
[`--enable-experimental-jit`](https://docs.python.org/dev/using/configure.html#cmdoption-enable-experimental-jit),
the uop executor's `jit_code` field is populated with a pointer to a compiled
C function that implement the executor logic. This function's signature is
defined by `jit_func` in [`pycore_jit.h`](Include/internal/pycore_jit.h).
When the executor is invoked by `ENTER_EXECUTOR`, instead of jumping to
the uop interpreter at `tier2_dispatch`, the executor runs the function
that `jit_code` points to. This function returns the instruction pointer
of the next Tier 1 instruction that needs to execute.

The generation of the jitted fuctions uses the copy-and-patch technique
which is described in
[Haoran Xu's article](https://sillycross.github.io/2023/05/12/2023-05-12/).
At its core are statically generated `stencils` for the implementation
of the micro ops, which are completed with runtime information while
the jitted code is constructed for an executor by
[`_PyJIT_Compile`](../Python/jit.c).

The stencils are generated under the build target `regen-jit` by the scripts
in [`/Tools/jit`](/Tools/jit). This script reads
[`Python/executor_cases.c.h`](../Python/executor_cases.c.h) (which is
generated from [`Python/bytecodes.c`](../Python/bytecodes.c)). For
each opcode, it constructs a `.c` file that contains a function for
implementing this opcode, with some runtime information injected.
This is done by replacing `CASE` by the bytecode definition in the
template file [`Tools/jit/template.c`](../Tools/jit/template.c).

Each of the `.c` file is compiled by LLVM, to produce an object file
that contains a function that executes the opcode. These compiled
functions are used to generate the file
[`jit_stencils.h`](../jit_stencils.h), which contains the functions
that the JIT can use to emit code for each of the bytecodes.

For Python maintainers this means that changes to the bytecodes and
their implementations do not require changes related to the JIT,
because everything the JIT needs is automatically generated from
[`Python/bytecodes.c`](../Python/bytecodes.c) at build time.

See Also:

* [Copy-and-Patch Compilation: A fast compilation algorithm for high-level languages and bytecode](https://arxiv.org/abs/2011.13127)

* [PyCon 2024: Building a JIT compiler for CPython](https://www.youtube.com/watch?v=kMO3Ju0QCDo)
